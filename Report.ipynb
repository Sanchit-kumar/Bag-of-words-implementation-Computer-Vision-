{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15c556b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial import distance\n",
    "from scipy import ndimage\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "n_test=0\n",
    "n_train=0\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "clusters_center=[]\n",
    "train_bovw_feature_dict={}\n",
    "test_bovw_feature_dict={}\n",
    "all_visual_feature_list=[]\n",
    "\n",
    "K_CLUSTER=105 ## Value of k find out by using k_cluster_value_selection which make graph between inertia vs K\n",
    "\n",
    "def readingData():\n",
    "    global n_test,n_train,x_train,y_train,x_test,y_test\n",
    "    train=pd.read_csv(\"fashion-mnist_train.csv\") #reading data from csv file\n",
    "    test=pd.read_csv(\"fashion-mnist_test.csv\") \n",
    "    \n",
    "    train_y_df=train[train.columns[0]]\n",
    "    train_x_df=train[train.columns[1:]]\n",
    "    test_y_df=test[test.columns[0]]\n",
    "    test_x_df=test[test.columns[1:]]\n",
    "\n",
    "#     n_test=test_x_df.shape[0]\n",
    "#     n_train=train_x_df.shape[0]\n",
    "    n_test=500\n",
    "    n_train=100\n",
    "\n",
    "    for i in range(n_test): #making train data and labels list\n",
    "        x_test.append(test_x_df.iloc[i].values.reshape(28,28).astype(np.uint8))\n",
    "        y_test.append(test_y_df.iloc[i])\n",
    "        \n",
    "    for i in range(n_train): #making train data and labels list\n",
    "        x_train.append(train_x_df.iloc[i].values.reshape(28,28).astype(np.uint8))\n",
    "        y_train.append(train_y_df.iloc[i])\n",
    "\n",
    "def make_dictionary(x,y,n): ###HELPER FUNCTION (MAKE DICTIONARY OF THE IMAGES OF SAME CATEGORY)\n",
    "    images={0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[],9:[]}\n",
    "    for i in range(n):\n",
    "        images[y[i]].append(x[i])\n",
    "    return images\n",
    "\n",
    "def feature_extractor(bovw_image_dict): ## It will extract the key point features from the images and group them\n",
    "                                        ## and return the all features from all images and dictionary of features w.r.t category\n",
    "    visual_feature_list = []\n",
    "    visual_feature_dict = {}\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    for key,images in bovw_image_dict.items():\n",
    "        extracted_features_list = []\n",
    "        for img in images:\n",
    "            keypoints, descriptor = sift.detectAndCompute(img,None)\n",
    "            if len(keypoints)<1:\n",
    "                continue\n",
    "            visual_feature_list.extend(descriptor)\n",
    "            extracted_features_list.append(descriptor)\n",
    "        visual_feature_dict[key] = extracted_features_list\n",
    "    return [visual_feature_list, visual_feature_dict]\n",
    "\n",
    "\n",
    "def kmeans(feature_descriptor,K=105): ## I AM USING K-MEANS ALGORITHM FOR MAKING THE CLUSTERS\n",
    "    model = KMeans(n_clusters = K, n_init=20, init='k-means++') ##Upto 20 iterations\n",
    "    model.fit(feature_descriptor)\n",
    "    visual_words_centers = model.cluster_centers_ \n",
    "    return [visual_words_centers,model]\n",
    "\n",
    "def kmeans_inertia(feature_descriptor,K): ##FINDING THE INERTIA, SO THAT WE CAN COMPARE WITH OTHER K VALUES TO FIND BEST K VALUE\n",
    "    model = KMeans(n_clusters = K, n_init=20, init='k-means++')\n",
    "    model.fit(feature_descriptor)\n",
    "    return model.inertia_\n",
    "\n",
    "def k_cluster_value_selection(feature_list): #it is used to plot the graph between inertial and k (#of clusters) to find the \n",
    "                                            # best value of the k\n",
    "\n",
    "    inertia=[]\n",
    "    values= [10*i for i in range(1,16)]\n",
    "    for k in values:\n",
    "        temp=kmeans_inertia(feature_list,k)\n",
    "        inertia.append(temp)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(values,inertia,marker='o')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.show()\n",
    "#     plt.savefig(\"K-value-selection.jpg\")\n",
    "\n",
    "\n",
    "\n",
    "def CreateDictionary(): ################# CREATING THE DICTIONARY ##############\n",
    "    readingData()\n",
    "    global clusters_center,train_bovw_feature_dict,test_bovw_feature_dict,all_visual_feature_list\n",
    "        \n",
    "    train_dict=make_dictionary(x_train,y_train,n_train) #it will create the dictionary of the category and images\n",
    "    test_dict=make_dictionary(x_test,y_test,n_test)\n",
    "    \n",
    "#     np.save(\"Visual_dict_train.npy\",train_dict) #saving the visual dictionary\n",
    "#     np.save(\"Visual_dict_test.npy\",test_dict)\n",
    "    \n",
    "\n",
    "    extracted_features= feature_extractor(train_dict)\n",
    "    all_visual_feature_list = extracted_features[0]\n",
    "    train_bovw_feature_dict = extracted_features[1] # bag of word of extracted features dictionary\n",
    "\n",
    "#     np.save(\"Visual_dict_extracted_features.npy\",train_bovw_feature_dict)\n",
    "    \n",
    "    test_bovw_feature_dict = feature_extractor(test_dict)[1]\n",
    "\n",
    "    [clusters_center,kmodel]= kmeans(all_visual_feature_list,K_CLUSTER)\n",
    "\n",
    "    \n",
    "    ### SAVING MOST CLOSEST VISUAL WORDS TO THE MEAN OF EACH CLUSTERS ###\n",
    "    \n",
    "    closest_indexs, _ = pairwise_distances_argmin_min(clusters_center,all_visual_feature_list) \n",
    "    closest_visual_word={}\n",
    "    for i in range(len(closest_indexs)):\n",
    "        closest_visual_word[i]=all_visual_feature_list[closest_indexs[i]]\n",
    "\n",
    "    np.save(\"closest_visual_word_dictionary_with_class.npy\",closest_visual_word) #saving \"dictionary class(key) to closest feature (value)\"\n",
    "    np.save(\"clusters_center_points.npy\",clusters_center) #K-class clusters center points from which closest feature in obtained\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ComputeHistogram(visual_dict_mat,clusters_center): #Assuming feature ventor is the center pointes of each cluster\n",
    "        \n",
    "        dict_feature = {}\n",
    "        k=len(clusters_center)\n",
    "        model= KMeans(n_clusters=k, init=clusters_center, max_iter=1) # loading kmeans model with previously features as cluster center points \n",
    "        model.fit(clusters_center) #using the same features as the center of teh clusters.\n",
    "                                    #So, kmean algorithm internally allot the unknown feature (to be predicted) to the nearest neighbour\n",
    "                                    # and hence giving the weight to the nearest neighbour\n",
    "        n=len(visual_dict_mat)\n",
    "        for i in range(n):\n",
    "            category = []\n",
    "            for img in visual_dict_mat[i]:\n",
    "                histogram = np.zeros(k) #INITIAL EMPTY HISTOGRAM, THE VALUES WILL BE ALLOCATED USING MODEL PREDICTION\n",
    "                                        # MODEL PREDICTION is not learning anything, but considering given centers of the cluster\n",
    "                                        # and predicting the class on the basis of its closeness in all clusters\n",
    "                for each_feature in img:\n",
    "                    label_class=model.predict([each_feature])[0]\n",
    "                    histogram[label_class] += 1\n",
    "                category.append(histogram)\n",
    "            dict_feature[i] = category\n",
    "        return dict_feature\n",
    "\n",
    "\n",
    "def MatchHistogram(hist1,hist2): #################\n",
    "    return 0.5*np.sum((hist1-hist2)**2/(hist1+hist2+1e-6)) ##chi square distance between two histogram\n",
    "#     return distance.euclidean(hist1,hist2) ### Euclidean distance between two histogram\n",
    "\n",
    "def KNN(histogram_bovw_train, histogram_bovw_test):\n",
    "    \n",
    "    confusion_matrix={}\n",
    "    for i in range(10):\n",
    "        confusion_matrix[i] = [0,0,0,0] #true +ve, total , false +ve,false -ve (true -ve not required, instead I took total)\n",
    "    total_test = 0\n",
    "    correct_predict = 0\n",
    "    \n",
    "    for tst_key, tst_value in histogram_bovw_test.items():\n",
    "        # confusion_matrix[tst_key] = [0,0,0,0] #true +ve, total , false +ve,false -ve (true -ve not required, instead I took total)\n",
    "        for tst in tst_value:\n",
    "            predicted_key =0\n",
    "            predict_start = 0\n",
    "            minimum_distance = 0\n",
    "            for train_key,train_value in histogram_bovw_train.items():\n",
    "                for train in train_value:\n",
    "                    if(predict_start == 0):\n",
    "                        minimum_distance = MatchHistogram(tst,train)  #calculating the euclidean distance\n",
    "                        predicted_key = train_key\n",
    "                        predict_start += 1\n",
    "                    else:\n",
    "                        dist = MatchHistogram(tst,train)\n",
    "                        if(dist < minimum_distance):\n",
    "                            minimum_distance = dist #updating the minimum eucledian distance\n",
    "                            predicted_key = train_key\n",
    "            \n",
    "            if(tst_key ==predicted_key):\n",
    "                confusion_matrix[tst_key][0] += 1\n",
    "                correct_predict += 1\n",
    "            else:\n",
    "                confusion_matrix[predicted_key][2]+=1 #updating false +ve\n",
    "                confusion_matrix[tst_key][3]+=1 #updatign false -ve\n",
    "            confusion_matrix[tst_key][1] += 1\n",
    "            total_test += 1\n",
    "\n",
    "    return [total_test, correct_predict, confusion_matrix] #this confusion matrix is customized cunfusion matrix\n",
    "\n",
    "def performance_matrix(result_matrix):\n",
    "    avg_acc = (result_matrix[1] / result_matrix[0]) * 100\n",
    "    print(\"Average accuracy: %\" + str(avg_acc))\n",
    "    print(\"\\nClass based performance: \\n\")\n",
    "    for key,value in result_matrix[2].items():\n",
    "        accuracy = (value[0] / value[1]) * 100\n",
    "        precision=(value[0]/(value[0]+value[2]))\n",
    "        recall=(value[0]/(value[0]+value[3]))\n",
    "        print(key,\"  Accuracy= %\",str(accuracy), \"Precision=\",str(precision), \"Recall:\",str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddafd509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88c5dd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0] global /tmp/pip-req-build-tvjus2qg/opencv_contrib/modules/xfeatures2d/misc/python/shadow_sift.hpp (13) SIFT_create DEPRECATED: cv.xfeatures2d.SIFT_create() is deprecated due SIFT tranfer to the main repository. https://github.com/opencv/opencv/issues/16736\n"
     ]
    }
   ],
   "source": [
    "CreateDictionary()  ### IT WILL ALSO SAVE MOST CLOSEST VISUAL WORDS TO THE MEAN OF EACH CLUSTERS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "075ec7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/cluster/_kmeans.py:984: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/cluster/_kmeans.py:984: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  self._check_params(X)\n"
     ]
    }
   ],
   "source": [
    "histogram_bovw_train = ComputeHistogram(train_bovw_feature_dict, clusters_center)  # Creates histograms for train data    \n",
    "\n",
    "histogram_bovw_test = ComputeHistogram(test_bovw_feature_dict, clusters_center) # Creates histograms for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd11964",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_matrix = KNN(histogram_bovw_train,histogram_bovw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dbaceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_matrix(result_matrix):\n",
    "    avg_acc = (result_matrix[1] / result_matrix[0]) * 100\n",
    "    print(\"Average accuracy: %\" + str(avg_acc))\n",
    "    print(\"\\nClass based performance: \\n\")\n",
    "    for key,value in result_matrix[2].items():\n",
    "        accuracy = (value[0] / value[1]) * 100\n",
    "        precision=(value[0]/(value[0]+value[2]))\n",
    "        recall=(value[0]/(value[0]+value[3]))\n",
    "        print(key,\"  Accuracy= %\",str(accuracy), \"Precision=\",str(precision), \"Recall:\",str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72fdfb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: %38.60434640165993\n",
      "\n",
      "Class based performance: \n",
      "\n",
      "0   Accuracy= % 74.0701381509033 Precision= 0.2236842105263158 Recall: 0.740701381509033\n",
      "1   Accuracy= % 41.97324414715719 Precision= 0.3653566229985444 Recall: 0.4197324414715719\n",
      "2   Accuracy= % 47.794117647058826 Precision= 0.33211678832116787 Recall: 0.47794117647058826\n",
      "3   Accuracy= % 22.308546059933406 Precision= 0.32682926829268294 Recall: 0.22308546059933407\n",
      "4   Accuracy= % 19.27835051546392 Precision= 0.3702970297029703 Recall: 0.19278350515463918\n",
      "5   Accuracy= % 46.790890269151134 Precision= 0.6034712950600801 Recall: 0.46790890269151136\n",
      "6   Accuracy= % 8.360477741585234 Precision= 0.23692307692307693 Recall: 0.08360477741585233\n",
      "7   Accuracy= % 40.08438818565401 Precision= 0.5337078651685393 Recall: 0.4008438818565401\n",
      "8   Accuracy= % 35.66289825282631 Precision= 0.7229166666666667 Recall: 0.3566289825282631\n",
      "9   Accuracy= % 49.442755825734544 Precision= 0.8160535117056856 Recall: 0.49442755825734547\n"
     ]
    }
   ],
   "source": [
    "performance_matrix(result_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e40e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
